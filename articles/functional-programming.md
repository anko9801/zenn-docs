---
title: "関数型ってなんなんだ"
emoji: "🦔"
type: "tech"
topics: ["関数型プログラミング"]
published: false
---

## 役立つ場面を教えてくれ

関数型プログラミングむずかしいがちですよね。

専門用語が多すぎるし、説明が長い！使う理由がよくわからない！シンプルで必要なことだけ書いて欲しい！

とそんな人が最近本腰を入れて関数型に向き合ってみた記録になります。実用性とはなんなのかから始まり、実用性に振り切った関数型プログラミングの解説をしてみました。

これを読む前に O'Reilly の Tidy First? を先に読んでおくとさらにわかると思います。これは単純な整頓から始まり、リファクタリングと経済がどのように繋がっているのかが描かれています。関数型プログラミングの話ではないですがかなり実用性のことを考えていて根幹となる考え方なので、ぜひ読んでみてください。

まだまだ理解できていない部分もあるので、ぜひコメントで意見を教えてください。

## もくじ

まずは関数型言語のメンタルの部分を説明します。

- いい言語ってなんだろう

その上で 3 つの疑問を紐解いていきます。

- 純粋関数っていみあんの？
- モナドっていみあんの？
- 圏論っていみあんの？

それが紐解けたら実務における話をします。

- 関数型を実用に落とし込むには

文章は誰でも読めるように書きますが具体例はあんまし書きませんし関数型言語である Haskell で書くので一度関数型を学んだことある人だと内容がスラスラ入ってくると思います。

## いい言語ってなんだろう

プログラミング言語に関するすべての技術は「リソース最適化」「開発を効率化する」という目的の為にあり、それは次の 3 つのどれかに当てはまると私は考えています。

1. わかりやすい
2. デバッグが楽ちん
3. 変更に強い

### わかりやすさ = ワーキングメモリの節約

まず 2 つの文を読んでください。

---

A: 私は昨日、駅の近くにある本屋で、プログラミングの本を買った。

B: 本を私は買った。昨日、プログラミングの本屋で、駅の近くにある。

---

明らかに文 A の方が読みやすい。理由は語順だ。関係のある単語が近くにあると、頭の負担が減る。 「駅の」と「近くにある」、「プログラミングの」と「本」が隣にいる。文 B ではこれらが離れている。 意味を繋ぎ合わせるために、頭の中で単語を保持しながら読まなければなりません。

この「頭の負担」を**認知負荷**といって頭の中のメモリである**ワーキングメモリを消費**します。容量は 5 〜 9 個の情報までで時間は約 20 秒しか持たない。キャパシティを越えると認知限界。わかりやすいとは、 **ワーキングメモリを節約する**ことです。実は数学が難しく感じるのは論理が難しいからではなくて、いろんな可能性を考えてる内に頭がパンクしちゃうからなのでした。

プログラミングでも同じことが言えます。大規模になるほど他の問題に比べて圧倒的に大きくなります。

以下のような工夫をすることで、よりわかりやすいコードを書くことができます。

| 浪費するワーキングメモリ  | 少ないワーキングメモリ |
| ------------- | ---------------- |
| 状態、オブジェクト | 値 |
| 可変性 | 不変性 |
| 深いネスト | 浅いネスト |
| 1 つの大きな部品 | モジュール化 |
| 実装が名前やコメントより軽い | 名前を省いて直接書く |
| 関係ないものが混在 | コロケーション |
| 重複が多い | Single Source of Truth |
| デッドコード | 消す |
| スパゲッティフロー | 単方向フロー |
| 副作用のあるロジック | 純粋関数 |
| 実装が複雑 | 実装がシンプル |
| 命令的 | 宣言的 |
| 依存関係の複雑さ | 合成的 |
| 長い再現しないコード | 最小の再現コード |

玉石混淆の情報を塊ごとに分けて整理するコロケーション。そうすると 1 つの情報を頭にと言って。それを階層構造は Single Source of Truth と単方向フローの組み合わせですし、

特にフロントエンドでは 1 つの状態が複数の UI に影響し、 1 つの UI 操作が複数の状態を変更する。このような複雑な循環構造をそのまま相互に依存するように書いてしまうと大規模になったときスパゲッティフローで依存関係が爆発してバグった時に疑わしい場所が数百個も出てきてそれがどこのフローから出現してどれが原因かわからなくなってしまう。これに対して View ⇄ Model ではなく View → Update → Model → View のような単方向フローにすることで依存関係を減らすことができます。これが The Elm Architecture や Redux などの状態管理アーキテクチャです。

Simple Made Easy という言葉がありますが、Simple は誰にとっても少ないワーキングメモリであり、Easy は主観的に手慣れたものです。常に Simple がいいという訳ではなくてその場に応じて Easy を取れる選択をすべきです。例えば for while if 文が 1 つの統一的で Simple な方法で記述できたとして最初から提供されている Easy を取った方がいいです。

ソフトウェア工学ではたくさんのルールがありますが、このワーキングメモリ 1 つ覚えておけばほぼ全てのことを説明できるのです。プログラミング以外でも UI/UX、発表、コミュニケーション、整理整頓、接客などなど非常に広範に適用できる考え方です。

ただ人間はこれを感じ取るのが不得意なので落ち着いて情報がいくつあるのかを数えると、仕事の効率が大きく上がります。


### デバッグが楽ちん = 合成的・代数的

大規模なシステムを構築するとき注意していないとデバッグが非常に困難になるので、予測可能性が高いことは重要であり、合成的であることはそれを保証します。そのため、合成的であることはバグが起きにくいことを保証します。

バグを見つけて直すとき次の手順を踏みます。

1. バグを再現する
2. 原因を特定する
3. 修正する
4. 確認する

合成的であるとはプログラム A とプログラム B を組み合わせてプログラム C を作ったときに C の性質が A, B の性質から分かることです。

例えば Recursion Schema における fold や map などは合成的であり、これらを組み合わせることでより複雑な操作を合成的に表現できます。

```typescript
const activeUsers = await getUsers()
  .map(user => getUserStatus(user))
  .filter(user => user.status === 'active')
  .catch(error => error.message);
```

ぬるぽやダングリングポインタ、並行処理など、どこにバグがあるのかわからないのは困る。

1. バグを再現する → Minimal Reproduction[^minimal] が作りやすい
2. 原因を特定する → どこまで不具合が起きていないかを確定しやすい
3. 修正する → 最小の変更で済む
4. 確認する → テストしやすい

副作用とロジックを分離する関数型言語はこれに直結します。

さらには代数的に設計すればバグが生まれないことを証明できます。例えば複雑な状態管理をするとき次のような落とし穴にはまりがちです。

```java
class Document {
    boolean isOpen;
    boolean isModified;
    boolean isSaving;
    // 全部で 8 通りの状態があるが、「閉じているのに保存中」などは無効
}
```

代数的データ型なら、直積型・直和型を用いることで不正な状態を型システムで排除でき、適切なモデル化ができます。

```haskell
-- あり得る状態だけ直和型で書き下せば不正な状態は絶対作られない
data Document = Closed 
              | Open Unmodified 
              | Open Modified 
              | Saving Content
```

このように代数を用いてシステムが健全であることを示せば必ずバグが起きません。関数型は型理論や圏論を元にしていて豊富な機能を揃えています。また非常に高いコストが必要ですが定理証明支援系を用いて C コンパイラの最適化処理 (CompCert) や OS のカーネルのセキュリティ (seL4) が健全であることを頑張って証明する形式手法があったりします。

### 変更に強い = 変わりにくいものに依存する

プロジェクトを進めると、仕様が変わる。データベースが PostgreSQL から MongoDB になる。UI が Web からモバイルアプリになる。決済方法が増える。

1 つの変更が次に波及すると、それに伴う変更が多数の変更を引き起こし、さらに変更が多数に伝播していく。サービス A がサービス B の API を使っていて、サービス A を変えるとそのサービス B も変えなければならない。こういったシステムは避けようと思っても往々にしてあると思います。

仕様変更に強いコードとは何か。

それは**変わりやすいものが、変わりにくいものに依存する**ことです。これにより変更の波及を最小化します。これを実践したのがクリーンアーキテクチャで「ドメイン ← ビジネスロジック ← 技術的詳細」と安定性と依存性が一致するように組み立てています。[^clean]

関数型ドメインモデリングではそのドメインを型で記述しています。

### つまり

3 つの性質を 3 つの原則に置き換えることができました。

1. わかりやすい = ワーキングメモリの節約
2. デバッグが楽ちん = 合成的・代数的
3. 変更に強い = 変わりにくいものに依存する

これらを満たすようなプログラミング言語を作れれば良さそうです。それが関数型言語なのです。

## 純粋関数っていみあんの？

関数型プログラミングを学び始めると最初に出会う重要な概念が純粋関数です。乱数生成や I/O、日付は純粋なのか？といった疑問が各地で議論されてます。

別に標準入出力あって特に困ったことなんてない。

その議論の前に整理することとして「純粋性」「副作用」「参照透過性」といった似た概念が混同されがちなので、 まずは定義をはっきりさせましょう。

### 定義

> **Def. 純粋性 (purity)**
> 決定性があり副作用がないこと
> - 決定性 : 同じ入力に対して常に同じ出力を返す
> - 副作用 : スコープ外の観測可能な状態に依存したり影響を与えたりする
 
> **Def. 参照透過性 (referential transparency)**
> 式をその結果で置き換えても、プログラムの意味が変わらない

副作用って言われたら例えばこんなものを想像してください。

- 状態への依存・変更 (可変参照、グローバル変数、キャッシュ、環境変数など)
- 入出力操作 (print、ファイルの読み書き、UI 操作など)
- 外部システムとの相互作用 (ネットワーク通信、データベース操作、センサー、エラーなど)

関数内に閉じた可変変数は、その関数から見れば副作用ではありません。しかし、その関数をさらに細かく分割すると、可変参照を渡さざるを得なくなり、分割後の関数から見れば副作用になります。

このように、何が副作用かはスコープによって変わります。ここでは「純粋関数」という個別の話ではなく、より広く「純粋性」という性質について議論します。

補足として冪等性との違いについてもはっきりさせておきましょう。

> **Def. 冪等性 (idempotence)**
> $x$ が冪等であるとは $x^2 = x$ を満たすこと、関数 $f(x)$ であれば $f(f(x)) = f(x)$ を満たすことです。

つまり関数を何度繰り返し適用しても 1 回適用したときと同じになる性質です。これは主に外部システムの状態を安全に変更させたいときに欲しい性質で、何度も install や update や delete すると毎回異なる結果になったら万一正常に動作しなかったとき大惨事なので、冪等性を持つように実装することで分散システムやインフラで運用の頑健性が向上します。

つまり純粋性も冪等性も何度処理を実行しても同じ結果になることは同じですが、ユースケースにおいて副作用を持つ持たないという点では真逆です。

### なぜ純粋関数が役立つのか

デバッグが楽ちん
合成的

副作用とロジックが混在したコードのデバッグを考えます。

バグを再現するとき、前者は「全ての状態を再現」する必要があり、後者は「引数を渡す」だけです。状態を再現するのは

副作用とロジックが分離していればどうでしょうか。

1. デバッグが楽になる
	- バグらせた時に原因の切り分けが楽
	- 引数のみに着目すればいいのでテストが楽にもなる
2. 認知負荷が減る
	- 追跡すべき状態が減って使用するワーキングメモリが減る
3. 独立に計算できるので並行処理・最適化がしやすい



そうは言ってもパフォーマンスのために局所的にミュータビリティを使ったり、I/O やネットワークなどはよく使います。そのために副作用は必ず影響範囲がどこかマークして限定し、その範囲外のコードは純粋に保つことができれば認知負荷の高い部分を最小限に抑えられます。Haskell は普段書いているプログラムはすべて純粋にしてその外側で副作用を扱って隠蔽しています。どう扱うかというと次の章のモナドを用いて表します。

## モナドっていみあんの？

純粋関数と型で世界をきれいに保てることはわかりました。しかし、現実のアプリケーションは「副作用」の塊です。データベースへの書き込み、API通信、ログ出力、エラーハンドリング。これらを純粋な世界でどう扱うか？ここで登場するのが、圏論由来の**モナド**です。

### モナドは「副作用」を「型」にする

モナド。それは悪名高く、次の言葉を毎日人から言われ続けてるのではないでしょうか。

「モナドは単なる自己関手の圏におけるモノイド対象だよ。何か問題でも？」[^2]

こんな言葉に惑わされなくていいです。実践的な観点から言えば、モナドは **「副作用を伴う計算」を「値」として扱い、安全に合成するためのデザインパターン** です。

lax monoidal functor歴史的にはホモロジー代数 Eugenio Moggi によってモナドを計算に導入する方法を非決定計算とかIOとか例外処理といった普通のプログラミング言語に備わっている言語機能をモジュール化することができるというところにある。モナドによって言語機能は次のようなものがあります。

- 失敗やエラー (Maybe モナド, Either モナド)
- 複数の結果 (List モナド)
- 副作用を隠蔽 (IO モナド, ST モナド)
- 状態と参照 (State モナド, Ref)
- アプリ全体で参照する変数 (Reader モナド, Writer モナド)
- ジェネレータ・コルーチン (Pipe モナド)
- パーサー (Megaparsec)
- 継続 (Cont モナド)
- 非同期処理 (Async, STM モナド)
- ストリーム処理 (Stream コモナド)
- 例外 (Except モナド)
- モナドを自然に構成 DI っぽいんよな〜 (Free モナド, Freer モナド)

全ての計算作用はモナドによって表現出来ます。(本当に？)こんなにもモナドによって表現できる機能は多いのです。

その答えを探る為にモナドの定義を見てみましょう。Haskell では Functor Applicative という型クラスを用いて Monad が定義されています。[^monad]

```haskell
class Functor (f :: Type -> Type) where
  fmap :: (a -> b) -> f a -> f b
  -- 恒等律: fmap id == id
  -- 合成律: fmap (g . f) == fmap g . fmap f

class (Functor f) => Applicative (f :: Type -> Type) where
  pure :: a -> f a
  (<*>) :: f (a -> b) -> f a -> f b
  -- 単位元: pure id <*> x = x
  -- 準同型: pure g <*> pure x = pure (g x)
  -- 交換: x <*> pure y = pure (\g -> g y) <*> x
  -- 結合: x <*> (y <*> z) = pure (.) <*> x <*> y <*> z

class (Applicative m) => Monad (m :: Type -> Type) where
  return :: a -> m a
  join :: m (m a) -> m a
  (>>=) :: m a -> (a -> m b) -> m b
  -- 左単位律: return a >>= f == f a
  -- 右単位律: m >>= return == m
  -- 結合律: (m >>= g) >>= h == m >>= (\x -> g x >>= h)
```

作用をもつ結合性を満たす計算は、モナド以外に

とても複雑ですね。まずは全体を見て共通する部分を洗い出します。どの型クラスも型から型へ変換して、恒等射と射の合成があるのですがそれぞれ射が微妙に異なっています。

例えば Maybe モナドであればそれぞれこんな感じで計算できます。

```haskell
fmap (+10) (Just 5) == Just 15
fmap (+10) Nothing == Nothing

pure (+) <*> Just 3 <*> Just 5 == Just 8
pure (+) <*> Just 3 <*> Nothing == Nothing

Just 100 >>= (\x -> safeDiv x 2) >>= (\y -> safeDiv y 5) == Just 10.0
Just 100 >>= (\x -> safeDiv x 0) >>= (\y -> safeDiv y 5) == Nothing
```

これらの射の表現力をあり得る関数の数 (型の濃度) で測ると次の表になります。本当に $f$でかけるの？

| 型クラス        | 恒等射      | 射の型          | 型の濃度     | Maybe モナドにおける射        |
| ----------- | -------- | ------------ | -------- | --------------------- |
| Functor     | `id`     | `a -> b`     | $b^a$    | なにも干渉できない             |
| Applicative | `pure`   | `f (a -> b)` | $f(b^a)$ | `Nothing` という定数関数ができる |
| Monad       | `return` | `a -> m b`   | $f(b)^a$ | 引数によって `Nothing` にできる |

ほうほう、少しずつ表現力が上がっているんですね。ちなみに Maybe モナドだと $f(x) = x + 1$ なので Applicative より Monad の方が表現力が高いけど、List モナドだと $f(x) = x^n$ なので同じ表現力です。

ちなみに Monad で型からすぐにはわかりにくい演算子 `>>=` を定義していますが、射 `a -> m b` のみを使うように形を整えて fish 演算子 `>=>` を作るとルールが見通しよくなります。

```haskell
(>=>) :: (a -> m b) -> (b -> m c) -> (a -> m c)
(>=>) f g = \x -> f x >>= g
-- 左単位律: return >=> f == f
-- 右単位律: f >=> return == f
-- 結合律: (f >=> g) >=> h == f >=> (g >=> h)
```

そしてこの `>>=` の由来して do 構文が生まれます。

```haskell
do
  s <- get
  put (s + 1)
  s' <- get
  put (s' * 2)
  get
```

do 構文はモナドを使った糖衣構文であり、脱糖すると次のようになります。

```haskell
get >>= (
  \s -> put (s + 1) >>= (
    \() -> get >>= (
      \s' -> put (s' * 2) >>=(
        \() -> get
      )
    )
  )
)
```

代入かと思われたものは前の結果を引数に入れていたのでした。構文が逐次的に処理することが分かってわかりやすいですね。

```haskell
input :: IO Int
input = do
  s <- get
  put (s + 1)
  s' <- get
  put (s' * 2)
  get
```

Haskell では `IO` モナドがとなります。`IO` 型の関数自体は純粋ですが内部実装で副作用を隠蔽しています。乱数や日付は `IO` モナドによって副作用があることがマークされます。

このように副作用を型に組み込むことで、副作用を扱う方法を代数的に扱うことが可能になります。

> **Def. Effect**
> 効果 (effect) とは観測可能な変化を引き起こす副作用 (side effect) を型に組み込んで代数的な扱いができるようになったもの。次を満たすもの

Effect は副作用と同じと思ってください。Effect を管理する方法を Effect System と呼びます。Effect System にはいくつかのライブラリがあります。

1 つの Effect であればモナドでうまく動くのですが、例えば標準入出力と乱数を使ったプログラムを書く時点でモナドは破綻します。なのでモナドを合成する手段が必要です。それがモナド変換子です。例えば `ReaderT IO ()` のように積み重ねていきます。

```haskell
main :: IO ()
main = do
  srand 111
  n <- rndInt 0 100
  print n
```

スタックが深くなるとパフォーマンスが悪化したり、`lift` で持ち上げるのが大変だったり、$N$ 個のモナドに対して $N^2$ 通りの組み合わせ（インスタンス）を定義しなければならないという「$N^2$ 問題」があります。

$N^2$ 問題を解決するため Extensible Effects というアプローチが生まれました。Open Union（拡張可能な直和型）を用いて複数の Effect を 1 つの `Eff` モナドにまとめ、ハンドラによって順次 Effect を解釈して取り除いていきます。Haskell では `freer-simple` や `polysemy` といったライブラリで実装されており、モナド変換子よりも合成しやすく、パフォーマンスも最適化しやすいという特徴があります。


### Algebraic effects & handlers

モナドをより分解することで問題を解決したのが Algebraic Effects です。

> モナドを操作 (operations) と等式 (equations) から構成する



Algebraic Effects & handlers は再開可能な型付き例外の言語機能として提供されており、Effect という例外を発生させると Handler に捕捉され、捕捉した継続を再開するかどうか、いつ、何回再開するかを制御します。こうするとモナドで扱っていた Effect は作れますし、さらには for 文、while 文、try-catch、イテレータ、Golang の defer、async/await、グリーンスレッド、アクターモデル、Rust の ? 演算子などなど[^effects]。Effect のみならずより広範な言語機能をユーザー定義のライブラリとして与えることができます。

```koka
```

例外と聞くと嫌悪感を抱く人が少なからずいるかもしれませんが、ご安心ください。例外の悪いところを整理すると catch したときに何の例外が発生したのかを型で明確にできるので

モナドよりもシンプルな概念で初心者にわかりやすいので広まって欲しいです。


## 圏論っていみあんの？

フレームワークは数年で廃れます。言語も流行り廃りがあります。しかし、その背後にある「計算の仕組み」や「構造」は変わりません。関数型プログラミングが強力なのは、その根底に数学（圏論・型理論）という普遍的な基盤があるからです。

### なぜ数学なのか

圏論、たくさん矢印を書いてるやつ

圏論を数学のさまざまな分野において普遍的にある性質を扱って証明をシンプルにする便利なツールとして使っていました。

「きれいな数学的理論に基づいてプログラミング言語を作れば、それは使いやすいものであるはずだ」という主張を元に導入されたもので、プログラミングに圏論を持ち込む必然的な理由はまだ見つかっていません。消極的な理由として圏論がプログラムをモデル化する唯一の既知の枠組みだったから。(論文が必要)

プログラミングにおける圏論はミスマッチが起きやすいので

これを納得していただきたいので圏論が導入されることになった歴史的経緯をお伝えします。

### 注意

どうしても正確な議論なしではわからないものが多いし冗長なので **ここからはお堅い数学の文章にモードシフトします。** 代数が未履修または苦手な人はごめんなさい、お菓子でも食べながら流し読みしてください。流れから雰囲気を感じ取ってほしいなと思います。
　
### 圏論導入以前と以後

コンピュータの誕生前、1936 年にアラン・チューリングがチューリングマシンを発表しました。これは 0 1 が書かれたメモリといくつかの規則であらゆる計算問題が解けてしまうという主張で現代のコンピュータの模型となる概念です。

同年にアロンゾ・チャーチは数学基礎論において関数を形式的に扱う為の方法としてラムダ計算を発表しました。そして翌年にチューリングはプリンストンでチャーチの元で学生となり、両者が計算能力において等価であることを証明して博士号を取りました。

このラムダ計算ってなんぞやというと、変数と関数抽象があってこの間でいくつかの推論をしていいよというルールを決めておきます。そうすると次のような推論ができます。

```
(λx. x * 2) ((λx. x + 1) 5)
→ (λx. x * 2) (5 + 1)
→ (λx. x * 2) 6
→ 6 * 2
→ 12

(λx. x x) (λx. x x)
→ (λx. x x) (λx. x x)
→ (λx. x x) (λx. x x)
→ ...

Y := λf. (λx. f (x x)) (λx. f (x x))

Y F
→ (λx. F (x x)) (λx. F (x x))
→ F ((λx. F (x x)) (λx. F (x x)))
→ F (Y F)
→ F (F (Y F))
→ F (F (F (Y F)))
→ ...
```

このようにラムダ計算では計算ができたり、不動点という今でいう再帰関数が作れたりして今のプログラムに近いことを数学上でシミュレートできるのです。

太古から積み上げてきた数学の知見に乗っかる為にラムダ計算を数学的な枠組みに落とし込もうと思います。
- 表示的意味論

ただしプログラムを数学に落とし込むのは非常にむずかしいです。例えば次のような問題があります。

1. 集合論での $D \cong D^D$
2. Effect の合成
3. 多相性からの定理導出

これらの詳細はこれから追ってくとして、すべてを解決する代数構造はあるのでしょうか。

**Entry No 1. ドメイン理論**
問題 $D\cong D^D$ は1930 年代にあった

型なしラムダ計算を集合論に落とし込もうとしたら、不動点を表す集合がなくて困りました。$\mathbf{Sets}$ で $D\cong D^D$ となる集合 $D$ は一点集合しかないので。

この問題は長らく解決されなかったが、これを上手く集合に落とし込んだのが 1969 年の Dana Scott のドメイン理論です。これはボトム要素 $\bot$ をもつ完備半順序集合 (CPO) を考えると問題を解決できるぞって発見です。なんぞやと言われるとざっくりプログラムが停止しない時の値を持ちつつ極限を考えられて順序がある集合なんですが具体的には次の $D_\infty$ が $D\cong D^D$ を満たす解の 1 つとなることがわかりました。

$$
\begin{aligned}
D_0 & := \{\bot\} \\
D_1 & := D_0 → D_0 \\
D_2 & := D_1 → D_1 \\
& \quad \vdots \\
D_\infty & := \bigcup_i Dᵢ
\end{aligned}
$$

ここから Kleene の不動点定理や Scott 連続関数などの定理が生まれ、上手くいってそうに見えますが、すべてが CPO という具体的な代数構造に縛れているし扱うのも複雑で厄介な構造でした。

結論、ラムダ式を具体的な集合として扱うのはむずかしかったけど、この試みは大きなインパクトを与えました。

**Entry No 2. 型理論**

チャーチは $D \cong D^D$ 問題で悩んでいた為、これを回避する為に、1940 年に単純型付きラムダ計算を発表しました。`λx: Int. x + 1` のように型という新しい概念を決めてあげて `λx. x x` のような型がマッチしないものは推論できないように制約を課したのです。表現力は落ちますが確実な方法です。

そしてこの型という概念が見事成功し、Curry-Howard 対応によってよくある証明図に型が書かれてあるあの形が現在主流になっています。

- 高階述語論理
- 型演算子
- 依存型
- Hindley Milner 型推論器が発明され、
- CPS, 限定継続
- 末尾再帰最適化
- Effect の合成

部分型
帰納型 再帰型
例えば Graded Modulality や Linear Types では変数は 1 度しか使えないという条件を加えて Rust における所有権やメモリのリソース最適化に役立ちます。

型推論に加えて値の条件も推論してくれる Liquid Types や

様相論理・線形時相論理

Microsoft が策定したエディタとエコシステム間のインターフェース Language Server Protocol (LSP) を使うことで型推論エンジンや型チェック、補完などの機能が実装コストが下がる。

型はバグのない最適化されたものを逐次検査してくれるものになるのでしょうか。

さて成功した型理論ですがさまざまな問題があります。
- 型理論の定理証明において非自明性を内在している
- 性質を扱う構造ができていなかった。

それに対する解決策としていくつかあり、ここでは圏論と HoTT について紹介します。

**Entry No 3. 圏論**

圏論は型理論に別の角度から意味を与える方法として使われています。

圏論はもともと代数的トポロジー、特にホモロジー論の技法として考案され、それが大数学者グロタンディークによって代数幾何に応用され、数学全般に適用されてきた経緯があります。

しかもこれまでの型付きラムダ計算をうまく説明することができるし、
今まで内部の構造を作って見える性質を考えていたのですが外側から見た性質だけで話そうというのが圏論の魅力です。

1950 年代後半に standard construction と呼ばれる構成が導入され、その圏論的性質を調べていく内にモナドという概念に辿り着きました。そして Eugenio Moggi がモナドを使うことで Effect を扱えることを示しました。

これらの発見を機に圏論を用いられるようになりました。

**Entry No 4. ホモトピー型理論 (HoTT)**

これは型理論をより数学基礎論の立場から強化する方法として扱われています。
トポロジーの枠組みを用いて型理論を構築する
帰納法を用いて証明する
構造に埋め込む
これまで「等しさ」を公理化することが
等しいという概念を定義せずとも
Cubical Type Theory は同値関係を Path で表し、連続写像を用いて証明を行います[^1lab]。

圏論のどこに表示的意味論と相性の良いものがあるのかを探し出して専門家たちの間で合意の取れるまで話し合い、その恩恵を実用で反映させてくというシステムにするのが効率いいので、実用の中で圏論を持ち出すのは割とナンセンスだと思っています。私たちは圏論を学ばずとも関数型や最新の動向をちゃんと知り、それを扱えるように情報を共有して。でも現状は論文を追うことはおろか関数型さえそんなに知れ渡っていない状態なので、もっとわかりやすい解説を増やしていきたいです。

さて圏論の意義がわかったところで。文量に限りがあるので圏論における定理の証明を解説するのはむずかしくそこは本を手にとってもらいたいのですが、ここでは幾つかの定義から読めることで味わっていきます。

### 圏論とは

圏論は関係を表す代数です。すべては対象と射に分けられて

> **Def. 圏**
> 圏 (category) $\mathscr{C}$ は次から構成されます:
> - 対象 (object) の集まり $\mathrm{Ob}(\mathscr{C})$
> - 射 (morphism) の集まり $\mathrm{Mor}(\mathscr{C})$
> 	- 対象 $A, B \in \mathrm{Ob}(\mathscr{C})$ に対して $A$ から $B$ への射の集まりを $\mathrm{Hom}_\mathscr{C}(A, B)$ と書き、射 $f\in \mathrm{Hom}_\mathscr{C}(A, B)$ は $f: A\to B$ と表す。
> - 射の合成 (composition): $f: A \to B$, $g: B \to C$ に対して $g \circ f: A \to C$
> 	- 恒等射の存在 (identity): 各対象 $A \in \mathrm{Ob}(\mathscr{C})$ に対して恒等射 (identity morphism) $\mathrm{id}_A: A \to A$ $\mathrm{id}_B: B\to B$ が存在し、任意の $f: A \to B$ に対して $$f \circ \mathrm{id}_A = f = \mathrm{id}_B \circ f$$
> 	- 結合律 (associativity): $f: A \to B$, $g: B \to C$, $h: C \to D$ に対して $$h \circ (g \circ f) = (h \circ g) \circ f$$

例:
- 圏 $\mathbf{Set}$ の対象は集合で、射は写像。
- 圏 $\mathbf{Grp}$ の対象は群で、射は群準同型写像。
- 圏 $\mathbf{Vect}_k$ の対象は体 $k$ 上のベクトル空間で、射は線形写像。
- 圏 $\mathbf{Top}$ の対象は位相空間で、射は連続写像。
- 圏 $\mathbf{Cat}$ の対象は小さい圏で、射は関手。
- 圏 $\mathbf{Hask}$ の対象はボトム $\bot$ を含んだ型で射は関数。

というようにさまざまな数学的対象が圏という枠組みに乗っているので、共通して成り立つ定理がいくつか存在します。

> **Def. 関手**
> 圏 $\mathscr{C}$, $\mathscr{D}$ に対して、関手 (functor) $F: \mathscr{C} \to \mathscr{D}$ は次から構成されます:
> - 対象関数: $\mathrm{Ob}(\mathscr{C})$ から $\mathrm{Ob}(\mathscr{D})$ への写像
    - $A \in \mathrm{Ob}(\mathscr{C})$ に対して $F(A) \in \mathrm{Ob}(\mathscr{D})$
> - 射関数: 各 $A, B \in \mathrm{Ob}(\mathscr{C})$ に対して $$F: \mathrm{Hom}_\mathscr{C}(A, B) \to \mathrm{Hom}_\mathscr{D}(F(A), F(B))$$
    - $f: A \to B$ に対して $F(f): F(A) \to F(B)$
> 1. **恒等射の保存**: 各対象 $A$ に対して $$F(\mathrm{id}_A) = \mathrm{id}_{F(A)}$$
> 2. **合成の保存**: $f: A \to B$, $g: B \to C$ に対して $$F(g \circ f) = F(g) \circ F(f)$$

**反変関手** (contravariant functor) $F: \mathscr{C} \to \mathscr{D}$ は $f: A \to B$ に対して $F(f): F(B) \to F(A)$ を与え、$F(g \circ f) = F(f) \circ F(g)$ を満たすもの。通常の関手は**共変関手** (covariant functor) とも呼ばれる。

Example.
- 忘却関手は代数構造を忘れるような
- 自由関手とは忘却関手が左随伴を持つ
- 自己関手

圏は既存の数学的対象を射のみを用いて書き換えるので

随伴

> **Def. デカルト閉圏**
> 圏 $\mathscr{C}$ がデカルト閉圏 (Cartesian closed category; CCC) であるとは、次を満たすことをいう:
> 1. 終対象 $1$ が存在する
> 2. 任意の対象 $A, B$ に対して積 $A \times B$ が存在する
> 3. 任意の対象 $A, B$ に対して指数対象 $B^A$ が存在する

例:
- $\mathbf{Set}$（集合の圏）: $B^A$ は関数空間 $A \to B$
- プログラミング言語の型の圏: $B^A$ は関数型 `A -> B`
- 前層の圏 $[\mathscr{C}^\mathrm{op}, \mathbf{Set}]$: 常にデカルト閉

デカルト閉圏では、関手 $- \times A: \mathscr{C} \to \mathscr{C}$ が右随伴 $(-)^A: \mathscr{C} \to \mathscr{C}$ を持つ: $$\mathrm{Hom}(C \times A, B) \cong \mathrm{Hom}(C, B^A)$$
つまりカリー化が行える。
**指数法則**:
- $(B \times C)^A \cong B^A \times C^A$
- $(C^B)^A \cong C^{B \times A}$
- $C^1 \cong C$
- $1^A \cong 1$

デカルト閉圏は型付きラムダ計算の意味論モデルを与える（Curry-Howard-Lambek対応）。

Kleisli triple からモナドを定義するんですが
コヒーレンス規則
すべてのモナドは関手の随伴対から得られる
コヒーレンス定理
パラメトリシティの自由定理
lax monoidal functor


さてここまで数学の話でしたが具体的にプログラムとの関係について考えてみましょう。

| Haskell の構造                   | 圏論的説明         | 主な用途    |
| ----------------------------- | ------------- | ------- |
| Monad/Applicative/Alternative | 自己関手の圏のモノイド対象 |         |
| Free/Cofree                   | 忘却関手の左随伴/右随伴  |         |
| Functor                       | 関手            | 構造を保つ写像 |
| Profunctor                    | 反変×共変の双関手     |         |
| End/Coend                     | 極限/余極限        |         |


## デザインパターン

これらのパターンに共通するのは、**「複雑な振る舞いを、合成可能な『値』として切り出す」** というアプローチです。

アプリケーション全体の構造をどう記述するか。
Algebraic Effects をアーキテクチャに落とし込む

*   **The Elm Architecture (TEA)**
    *   **記述**: `Msg`（何が起きたか）と `Model`（現在の状態）。
    *   **解釈**: `update` 関数が `Msg` を解釈して次の `Model` を決定する。
    *   UI の状態遷移を「メッセージという値」として扱うことで、予測可能な単方向データフローを実現します。

*   **Cake Pattern / ReaderT Pattern**
    *   **記述**: 依存関係（DB接続や設定）を型（`ReaderT Config m a` や `Component` インターフェース）として記述。
    *   **解釈**: アプリケーションの起動時に具体的な依存性を注入（`runReaderT`）して実行。
    *   DI（依存性の注入）を関数合成やモナドの仕組みで実現します。

*   **Tagless Final / Free Monad**
    *   **記述**: ドメイン固有言語（DSL）として「やりたいこと」を型クラスやデータ型で定義。
    *   **解釈**: それを本番用（DBアクセス）、テスト用（オンメモリ）、モック用などに自由に差し替えるインタプリタを用意。
    *   「DBに保存する」という行為自体を抽象的な値として扱うことで、テスト容易性と移植性を極限まで高めます。

*   **Railway Oriented Programming (ROP)**
    *   **記述**: 成功と失敗の分岐を `Result` や `Either` という型で表現。
    *   **解釈**: `bind` (`>>=`) や合成関数を使って、失敗する可能性のある処理をレールのように繋げる。
    *   エラー処理の `if err != nil` 地獄から解放され、正常系と異常系を一本のパイプラインとして記述できます。

*   **Optics (Lens / Prism)**
    *   **記述**: 深いネストにあるデータへのアクセス方法（Getter/Setter）を `Lens` という値として記述。
    *   **解釈**: その `Lens` を使って、不変データを安全かつ簡潔に読み書き（コピーして更新）する。
    *   `user.address.city` のようなアクセスを、オブジェクト指向のミュータブルな操作と同じくらい手軽に、かつ関数的に合成可能な形で行えます。

*   **Recursion Schemes**
    *   **記述**: 再帰的なデータ構造（木構造など）の「形」を Functor で記述。
    *   **解釈**: `cata` (畳み込み) や `ana` (展開) といった高階関数を使って、再帰のロジック（どう走査するか）とビジネスロジック（各ノードで何をするか）を分離。
    *   再帰につきものの無限ループやスタックオーバーフローのバグを防ぎつつ、再帰処理を部品化します。

### まとめ


[^minimal]: [OSS貢献を「依頼」から「協力」に変える、Issueとプルリクエストの書き方](https://findy-code.io/media/articles/codesidechat-sapphi_red_ja)
[^2]: [A Brief, Incomplete, and Mostly Wrong History of Programming Languages](https://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html)
[^clean]: [世界一わかりやすいClean Architecture - 技術レイヤー分割より大切なモノ](https://www.docswell.com/s/nuits_jp/5DNXE9-easiest-clean-architecture)
[^monads]: [Notions of computation and monads](https://person.dibris.unige.it/moggi-eugenio/ftp/ic91.pdf)
[^5]: [Notions of Computation Determine Monads](https://dl.acm.org/doi/10.5555/646794.704856)
[^6]: [Freer Monads, More Extensible Effects](http://okmij.org/ftp/Haskell/extensible/more.pdf)
[^7]: https://ktgw0316.github.io/milewski-ctfp-markdown/
[^recursion]: [An introduction to recursion schemes](https://nrinaudo.github.io/recursion-schemes-from-the-ground-up/)
[^monad]: 概念ならモナド、型クラスなら Monad と書きます
[^state]: [React ステート管理 比較考察](https://blog.uhy.ooo/entry/2021-07-24/react-state-management/)
[^1lab]: [1Lab](https://1lab.dev/)
[^tagless]: [Typed Tagless Final Interpreters](https://okmij.org/ftp/tagless-final/course/lecture.pdf)
[^effects]: [yallop/effects-bibliography](https://github.com/yallop/effects-bibliography)

